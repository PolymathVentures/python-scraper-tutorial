# Crear un scraper en Python en menos de 10 minutos

Algunas p√°ginas pueden tener informaci√≥n que es valiosa para nuestro negocio o para entender mejor un mercado, normalmente si queremos extraer la informaci√≥n de estas p√°ginas nuestra primera opci√≥n ser√≠a realizar un proceso manual engorroso que consumir√≠a mucho tiempo y esfuerzo de una o varias personas, afortunadamente para estos casos los scripts de programaci√≥n con python pueden ayudarnos a no solo ahorrar tiempo si no hacer los procesos de forma autom√°tica o masiva.

## ¬øQu√© es un scraper y en qu√© casos lo necesito?
Es el proceso por el cual de forma autom√°tica minamos, extraemos y almacenamos datos de una p√°gina web por el protocolo http, es decir, un web scraper es un programa que utilizamos para obtener grandes cantidades de datos de una p√°gina web de una forma automatizada, es como si un robot leyera toda la informaci√≥n y extrae la que le indiquemos

Para poder hacer web scraping se deben realizar dos procesos:
 - Fetching: obtener o descargar el contenido de la p√°gina por el protocolo http
 - Extracting: Extraer los datos que queremos de la p√°gina

## ¬øQu√© vamos a construir?
En este tutorial de PolyMathDevs vamos a ver c√≥mo desarrollar un web scraper con python sobre la pagina web https://www.imdb.com/chart/top/  en la cual nos muestra una lista de las 250 mejores pel√≠culas

![Screenshot](website.png)

Una vez desarrollemos nuestro script tomar√° la informaci√≥n del nombre de la pelicula, a√±o de lanzamiento y calificaci√≥n y nos guardar√° esta informaci√≥n en un csv c√≥mo se puede ver a continuaci√≥n:

![Screenshot](csv.png)

## Contrucci√≥n del scraper:
Para poder realizar el scraper lo primero que vamos a realizar es obtener el contenido de la p√°gina web que estamos realizando el scraper en nuestro caso es https://www.imdb.com/chart/top/, esto lo realizamos por medio de la librer√≠a request de python y para poder manejar el contenido de la p√°gina de una forma mas clara utilizaremos la librer√≠a BeautifulSoup.

- Requests: Liberia HTTP de python para hacer http request mas faciles
- BeautifulSoup: M√≥dulo de la librer√≠a BS4 de python que analiza la pagina y extrae la informaci√≥n que le indicamos y la formatea para que sea m√°s f√°cil de manipular

Debemos instalar las librer√≠as
```bash
  pip install requests bs4
```

Si no lo puedes realizar con pip puedes validar con pip3

Para validar que est√© bien creamos un nuevo archivo scraper.py donde importamos las librerias
```python
import requests ,bs4
from bs4 import BeautifulSoup
```

Ejecutamos el script scraper.py 
```bash
  python scraper.py
```

Si no lo puedes realizar con python puedes validar con python3 scraper.py 

![Screenshot](goodrun.jpg)

Si al ejecutar el script no obtenemos ning√∫n error significa que tenemos bien instaladas las librer√≠as üëç, ahora obtenemos la p√°gina web con request agregando las siguientes lineas a nuestro archivo scraper.py 
```python
url = 'https://www.imdb.com/chart/top/'
page = requests.get(url)
```

Como ya tenemos nuestra pagina web ahora vamos a utilizar BeautifulSoup para poder obtener directamente cualquier tag o elemento html que deseemos, para esto agregamos la siguiente linea nuestro script scraper.py 
```python
format_page =  BeautifulSoup(page.content, 'html.parser')
```



Ya con nuestra p√°gina en nuestro objeto format_page formateada podemos navegar por el contenido html de la p√°gina que obtuvimos con requests y extraer la informaci√≥n, antes de hacer esto veamos algunos ejemplos de c√≥mo podemos obtener informaci√≥n con BeautifulSoup

Podemos extraer contenido de BeautifulSoup con los siguientes comandos:

| Acci√≥n | Codigo  |
| ------- | --- |
| Obtener el t√≠tulo de la p√°gina el elemento <title> | format_page.title |
| Obtener el body de la p√°gina el elemento <body> | format_page.body |
| Obtener el primer div que se encuentra en el body | format_page.body.div |
| Obtener todos los div‚Äôs que est√°n en la p√°gina | format_page.find_all('div') |
| Obtener todos los div‚Äôs que est√°n en la p√°gina con una clase* espec√≠fica | format_page.find_all('div', class_='subnav_item_main') |
| Obtener el div‚Äôs que est√°n en la p√°gina con un id especifico | format_page.find_all('div', id='success-story-929') |

> *En python la palabra class es reservada es por esto que en este m√©todo debemos pasarle el identificador class_ si quisi√©ramos utilizar la palabra reservada class debemos pasarla como un atributo como se muestra a continuaci√≥n
```python
format_page.find_all('div', {'class':success-story-item})
```

Es importante tener presente que el contenido que retorna BeautifulSoup no es de tipo text si no de tipo tag , estamos obteniendo directamente todo el elemento tag del html
```python
print(type(format_page.body.div))
```
Si queremos obtener el contenido dentro del tag html debemos utilizar el m√©todo text
```python
print(format_page.body.div.text)
```

Teniendo lo anterior claro ahora vamos ha realizar el scraper, para esto lo primero es definir qu√© datos queremos obtener es diferente si queremos traer todo un objeto o s√≥lo cierta informaci√≥n, para nuestro ejemplo vamos a obtener el t√≠tulo , la fecha de estreno y el rating de cada una de las 250 pel√≠culas que est√°n en la lista

Para esto vamos a utilizar el inspector de c√≥digo sobre la p√°gina para validar que informaci√≥n tienen en com√∫n los bloques o c√≥mo est√°n construidos para poder identificar qu√© par√°metro es sobre el cual vamos a realizar la b√∫squeda

![Screenshot](inspect1.jpg)

Como podemos ver en la imagen todas las listas est√°n en una tabla con la clase ‚Äúlister-list‚Äù y dentro de este tabla cada pel√≠cula ocupa una fila , lo primero que realizaremos es obtener el body de la tabla con la clase ‚Äúlister-list‚Äù, para esto agregamos la siguiente l√≠nea a nuestro script
```python
tbody = format_page.find('tbody', class_='lister-list')
```

Ahora que ya tenemos la tabla podemos obtener cada fila de la pelicula realizando un loop sobre los elementos de la tabla
```python
for movie in tbody.find_all('tr'):
	print(movie)
```

Si vemos el resultado de ejecutar nuestros script encontramos que ya tenemos el elemento tr , ahora debemos ir al detalle de cada celda para obtener:
![Screenshot](output.jpg)
### El nombre:
![Screenshot](inspect2.jpg)
El nombre se encuentra dentro de la fila tr en una celda td con la clase ‚ÄútitleColum‚Äù y dento de un tag de enlace <a> , para poder obtenerlo agregamos la siguiente linea
```python
title = movie.find('td', {'class':'titleColumn'}).a.text 
```

### El a√±o de lanzamiento:
![Screenshot](inspect3.jpg)
El a√±o de lanzamiento se encuentra dentro de la misma celda td que el nombre, solo que se encuentra dentro de un tag <span>
```python
year = movie.find('td', class_='titleColumn').span.text
```

### La Calificaci√≥n(Rating):
![Screenshot](inspect4.jpg)
La Calificaci√≥n se encuentra dentro de la celda td con la clase ‚ÄúimdbRating‚Äù y dentro de un tag <strong>
```python
rating = movie.find('td', class_='imdbRating').strong.text
```


Dando por resultado final que nuestros script sea de la siguiente forma:
```python
import requests ,bs4
from bs4 import BeautifulSoup

url = 'https://www.imdb.com/chart/top/'
page = requests.get(url)
format_page =  BeautifulSoup(page.content, 'html.parser')
tbody = format_page.find('tbody', class_='lister-list')

for movie in tbody.find_all('tr'):
	title = movie.find('td', {'class':'titleColumn'}).a.text
	year = movie.find('td', class_='titleColumn').span.text
	rating = movie.find('td', class_='imdbRating').strong.text
```
	
## Guardando los datos en un archivo csv:
Ya que logramos tener toda la informaci√≥n de las pel√≠culas que deseamos ahora vamos a almacenarla en un archivo csv, para esto vamos a importar la librer√≠a csv
```python
import csv
```
Vamos a abrir el documento csv donde vamos a guardar nuestras pel√≠culas(movies.csv) y vamos a crear un writer para poder escribir en el  
```python
f = open('movies.csv', 'w')
writer = csv.writer(f)
```

Primero agregamos los headers
```python
header = ['Title', 'ReleaseDate', 'Rating']
writer.writerow(header)
```

Y vamos a guardar la informaci√≥n de cada pel√≠cula mientras recorremos la lista de objetos writer.writerow([title,year,rating])

Por √∫ltimo cerramos el documento movies.csv
```python
f.close()
```

Y nuestro c√≥digo completo quedar√≠a de la siguiente manera:
```python
import requests ,bs4
from bs4 import BeautifulSoup
import csv

url = 'https://www.imdb.com/chart/top/'
page = requests.get(url)
format_page =  BeautifulSoup(page.content, 'html.parser')
tbody = format_page.find('tbody', class_='lister-list')

f = open('movies.csv', 'w')
writer = csv.writer(f)

header = ['Title', 'ReleaseDate', 'Rating']
writer.writerow(header)

for movie in tbody.find_all('tr'):	
	title = movie.find('td', {'class':'titleColumn'}).a.text
	year = movie.find('td', class_='titleColumn').span.text
	rating = movie.find('td', class_='imdbRating').strong.text
	writer.writerow([title,year,rating])

f.close()
```


**Importante:** es necesario que cuando realices un scraping tengas presente las pol√≠ticas de la p√°gina que deseas scrapear para estar seguro que no se est√° infringiendo ninguna ley, esta validaci√≥n la puedes realizar tambi√©n ingresando al dominio principal del sitio y agregando /robots.txt donde puedes validar si la url sobre la que est√°s realizando el scraper est√° autorizada o no , para nuestro ejemplo vamos a utilizar la p√°gina de imdb s√≥lo con fines educativos

## Conclusiones finales
Con unas pocas l√≠neas de c√≥digo es posible obtener la informaci√≥n de alguna p√°gina de forma ordenada y autom√°tica, esto nos puede funcionar para hacer una migraci√≥n masiva de datos de un sitio a otro , para estudios de mercado o para tener informaci√≥n confiable en tiempo real, si te gusto este contenido y quieres que te notifiqumos cuando publiquemos algo nuevo inscribete en nuestro newsletter aqu√≠.

